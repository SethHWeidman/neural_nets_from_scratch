{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Working network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# sigmoid function\n",
    "def nonlin(x,deriv=False):\n",
    "    if(deriv==True):\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# input dataset\n",
    "X = np.array([  [0,0,1],\n",
    "                [0,1,1],\n",
    "                [1,0,1],\n",
    "                [1,1,1] ])\n",
    "    \n",
    "# output dataset            \n",
    "y = np.array([[0,0,1,1]]).T\n",
    "\n",
    "# seed random numbers to make calculation\n",
    "# deterministic (just a good practice)\n",
    "np.random.seed(1)\n",
    "\n",
    "# initialize weights randomly with mean 0\n",
    "syn0 = 2*np.random.random((3,1)) - 1\n",
    "\n",
    "for iter in xrange(1000):\n",
    "\n",
    "    # forward propagation\n",
    "    l1 = nonlin(np.dot(X,syn0))\n",
    "    \n",
    "    # how much did we miss?\n",
    "    l1_error = y - l1\n",
    "\n",
    "    # multiply how much we missed by the\n",
    "    # slope of the sigmoid at the values in l1\n",
    "    l1_delta = l1_error * nonlin(l1,True)\n",
    "\n",
    "    # update weights\n",
    "    syn0 += np.dot(X.T,l1_delta)\n",
    "\n",
    "print \"Output After Training:\"\n",
    "print syn0\n",
    "print l1_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Clean one layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# sigmoid function\n",
    "def sigmoid(x,deriv=False):\n",
    "    if(deriv==True):\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# input dataset\n",
    "X = np.array([  [0,0,1],\n",
    "                [0,1,1],\n",
    "                [1,0,1],\n",
    "                [1,1,1],\n",
    "                [1,0,1]])\n",
    "    \n",
    "# output dataset            \n",
    "y = np.array([[0,0,1,1,1]]).T\n",
    "\n",
    "# seed random numbers to make calculation\n",
    "# deterministic (just a good practice)\n",
    "np.random.seed(1)\n",
    "\n",
    "# initialize weights randomly with mean 0\n",
    "W = np.random.randn(3, 1)\n",
    "\n",
    "for iter in xrange(1000):\n",
    "\n",
    "    # forward propagation\n",
    "    A = np.dot(X,W)\n",
    "    H = sigmoid(A)\n",
    "    \n",
    "    # how much did we miss?\n",
    "    L = 0.5 * ( y - H ) ** 2\n",
    "    \n",
    "    dLdH = -1.0 * (y - H)\n",
    "    \n",
    "    dHdA = sigmoid(H, True)\n",
    "\n",
    "    # multiply how much we missed by the\n",
    "    # slope of the sigmoid at the values in l1\n",
    "    dLdA = dLdH * dHdA\n",
    "    \n",
    "    # xij = observation i, feature j\n",
    "    # A1 = w1 * x11 + w2 * x12 + w3 * x13\n",
    "    # A2 = w1 * x21 + w2 * x22 + w3 * x23\n",
    "    # A3 = w1 * x31 + w2 * x32 + w3 * x33\n",
    "    \n",
    "    dAdW = X.T\n",
    "    \n",
    "    # 3 x 1 = 3 x n * n x 1\n",
    "    dLdW = np.dot(dAdW, dLdA)\n",
    "    # Weight i, observation j is updated by sum(j=1^n) (Xi * dLdA),\n",
    "    # where j runs over all the observations\n",
    "    # times the product of the other derivatives,\n",
    "    # as we expect \n",
    "    \n",
    "    # dA / dW = [[x11 x12 x13]\n",
    "    #            [x21 x22 x23]\n",
    "    #            ...\n",
    "    #            [xn1 xn2 xn3]]\n",
    "    # dLdA = [A1 A2 ... An]\n",
    "    \n",
    "    # update weights\n",
    "    # w1 -= A1 * x11 + A2 * x21 + ... + An * xn1\n",
    "    # w2 -= A1 * x12 + A2 * x22 + ... + An * xn2\n",
    "    # w3 -= A1 * x13 + A2 * x23 + ... + An * xn3\n",
    "    W -= dLdW\n",
    "\n",
    "print \"Output After Training:\"\n",
    "print W\n",
    "print H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Two layer network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(x,deriv=False):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#### import numpy as np\n",
    "import math\n",
    "\n",
    "# sigmoid function\n",
    "def sigmoid(x,deriv=False):\n",
    "    if(deriv==True):\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "\n",
    "# input dataset\n",
    "X = np.array([[0,0,1]])\n",
    "    \n",
    "# output dataset            \n",
    "y = np.array([[1]]).T\n",
    "\n",
    "# seed random numbers to make calculation\n",
    "# deterministic (just a good practice)\n",
    "np.random.seed(1)\n",
    "\n",
    "# initialize weights randomly with mean 0\n",
    "V = np.random.randn(3, 4)\n",
    "W = np.random.randn(4, 1)\n",
    "\n",
    "for i in xrange(1000):\n",
    "\n",
    "    # forward propagation\n",
    "    A1 = np.dot(X,V)\n",
    "    A2 = sigmoid(A1)\n",
    "    \n",
    "    B1 = np.dot(A2,W)\n",
    "    B2 = sigmoid(B1)\n",
    "    \n",
    "    L = 0.5 * ( y - B2 ) ** 2\n",
    "    \n",
    "    # n x 1\n",
    "    dLdB2 = -1.0 * (y - B2)\n",
    "\n",
    "    # n x 1\n",
    "    dB2dB1 = sigmoid(B2, deriv=True) \n",
    "\n",
    "    # n x 1 = n x 1 * n x 1\n",
    "    dLdB1 = dLdB2 * dB2dB1\n",
    "    \n",
    "    # 4 x n\n",
    "    dB1dW = A2.T\n",
    "    \n",
    "    # 4 x 1\n",
    "    dB1dA2 = W\n",
    "    \n",
    "    # n x 4\n",
    "    dA2dA1 = sigmoid(A2, deriv=True)\n",
    "\n",
    "    # n x 1 = n x 4 * 4 x 1 \n",
    "    dB1dA1 = np.dot(dA2dA1, dB1dA2)\n",
    "\n",
    "    # 3 x n\n",
    "    dA1dV = X.T\n",
    "    \n",
    "    # n x 1 = n x 1 * n x 1\n",
    "    dLdA1 = dB1dA1 * dLdB1 \n",
    "    \n",
    "    # 3 x 1 = 3 x n * n x 1\n",
    "    # dLdA1 has to be n x 4\n",
    "    dLdV = np.dot(dA1dV, dLdA1) \n",
    "    \n",
    "    W -= 0.5 * dLdW\n",
    "    \n",
    "    V -= 0.5 * dLdV  \n",
    "\n",
    "print \"Output After Training:\"\n",
    "print np.mean(L)\n",
    "print B2\n",
    "\n",
    "A2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Code for deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Initialize the X and y arrays\n",
    "x1 = 0\n",
    "x2 = 0\n",
    "x3 = 1\n",
    "y1 = 1\n",
    "\n",
    "import numpy as np\n",
    "X = np.array([[x1,x2,x3]])\n",
    "y = np.array([[y1]]).T\n",
    "\n",
    "# Initialize `V`\n",
    "V = np.random.randn(3, 4)\n",
    "\n",
    "# Multiply `X` by `V`\n",
    "A = np.dot(X,V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "B = sigmoid(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Two layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def nonlin(x,deriv=False):\n",
    "\tif(deriv==True):\n",
    "\t    return x*(1-x)\n",
    "\treturn 1/(1+np.exp(-x))\n",
    "    \n",
    "X = np.array([[0,0,1],\n",
    "            [0,1,1],\n",
    "            [1,0,1],\n",
    "            [1,1,1]])\n",
    "                \n",
    "y = np.array([[0],\n",
    "\t\t\t[1],\n",
    "\t\t\t[1],\n",
    "\t\t\t[0]])\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# randomly initialize our weights with mean 0\n",
    "V = 2*np.random.random((3,4)) - 1\n",
    "W = 2*np.random.random((4,1)) - 1\n",
    "\n",
    "for j in xrange(60000):\n",
    "\n",
    "\t# Feed forward through layers 0, 1, and 2\n",
    "    A1 = np.dot(X,V)\n",
    "    A2 = nonlin(A1)\n",
    "    B1 = np.dot(A2,W)\n",
    "    P = nonlin(B1)\n",
    "\n",
    "    # how much did we miss the target value?\n",
    "    B2_error = y - P\n",
    "    \n",
    "    if (j% 10000) == 0:\n",
    "        print \"Error:\" + str(np.mean(np.abs(B2_error)))\n",
    "        \n",
    "    # in what direction is the target value?\n",
    "    # were we really sure? if so, don't change too much.\n",
    "    B2_delta = B2_error*nonlin(P,deriv=True)\n",
    "\n",
    "    # how much did each l1 value contribute to the l2 error (according to the weights)?\n",
    "    A2_error = B2_delta.dot(W.T)\n",
    "    \n",
    "    # in what direction is the target l1?\n",
    "    # were we really sure? if so, don't change too much.\n",
    "    A1_delta = A2_error * nonlin(A2,deriv=True)\n",
    "\n",
    "    W += A2.T.dot(B2_delta)\n",
    "    V += X.T.dot(A1_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dLdV = dAdV.dot(dLdP*dPdC.dot(dCdB) * dBdA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def nonlin(x,deriv=False):\n",
    "\tif(deriv==True):\n",
    "\t    return x*(1-x)\n",
    "\treturn 1/(1+np.exp(-x))\n",
    "    \n",
    "X = np.array([[0,0,1],\n",
    "            [0,1,1],\n",
    "            [1,0,1],\n",
    "            [1,1,1],\n",
    "             [1,1,0],\n",
    "             [0,0,0],\n",
    "             [0,1,0]])\n",
    "                \n",
    "y = np.array([[0],\n",
    "              [0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [1],\n",
    "              [1],\n",
    "             [1]])\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# randomly initialize our weights with mean 0\n",
    "V = np.random.randn(3, 4)\n",
    "W = np.random.randn(4, 1)\n",
    "\n",
    "for j in xrange(60000):\n",
    "\n",
    "\t# Feed forward through layers 0, 1, and 2\n",
    "    A = np.dot(X,V)\n",
    "    B = nonlin(A)\n",
    "    C = np.dot(B,W)\n",
    "    P = nonlin(C)\n",
    "\n",
    "    # how much did we miss the target value?\n",
    "    L = 0.5 * (y - P) ** 2\n",
    "    \n",
    "    if ( j % 10000) == 0:\n",
    "        print \"Error:\" + str(np.mean(np.abs(L)))\n",
    "        \n",
    "    # in what direction is the target value?\n",
    "    # were we really sure? if so, don't change too much.\n",
    "    dLdP = -1.0 * (y-P)\n",
    "    \n",
    "    dPdC = nonlin(P,deriv=True)\n",
    "\n",
    "    dLdC = dLdP*dPdC\n",
    "\n",
    "    dCdW = B.T\n",
    "    \n",
    "    dLdW = dCdW.dot(dLdC)\n",
    "    \n",
    "    dCdB = W.T\n",
    "    \n",
    "    dLdB = dLdC.dot(dCdB)\n",
    "    \n",
    "    dBdA = nonlin(B,deriv=True)\n",
    "    \n",
    "    dLdA = dLdB * dBdA\n",
    "    \n",
    "    dAdV = X.T\n",
    "    \n",
    "    dLdV = dAdV.dot(dLdA)\n",
    "\n",
    "    # W (4 x 1) = A2.T (4 x n) * B2_delta (n x 1)\n",
    "    W -= dLdW \n",
    "    \n",
    "    # V (3 x 4) = X.T (3 x n) * A1_delta (n x 4)\n",
    "    V -= dLdV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dCdW = B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x,deriv=False):\n",
    "\tif(deriv==True):\n",
    "\t    return x*(1-x)\n",
    "\treturn 1/(1+np.exp(-x))\n",
    "\n",
    "X = np.array([[0,0,1],\n",
    "            [0,1,1],\n",
    "            [1,0,1],\n",
    "            [1,1,1],\n",
    "             [1,1,0],\n",
    "             [0,0,0],\n",
    "             [0,1,0]])\n",
    "                \n",
    "y = np.array([[0],\n",
    "              [0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [1],\n",
    "              [1],\n",
    "             [1]])\n",
    "V = np.random.randn(3, 4)\n",
    "W = np.random.randn(4, 1)\n",
    "for j in range(60000):\n",
    "    A = np.dot(X,V)\n",
    "    B = nonlin(A)\n",
    "    C = np.dot(B,W)\n",
    "    P = nonlin(C)\n",
    "    L = 0.5 * (y - P) ** 2\n",
    "    if ( j % 10000) == 0:\n",
    "        print \"Error:\" + str(np.mean(np.abs(L)))\n",
    "    dLdP = -1.0 * (y-P)\n",
    "    dPdC = sigmoid(C) * (1-sigmoid(C))\n",
    "    dLdC = dLdP * dPdC\n",
    "    dCdW = B.T\n",
    "    dLdW = np.dot(dCdW, dLdC)\n",
    "    dCdB = W.T\n",
    "    dLdB = dLdC * dCdB\n",
    "    dBdA = sigmoid(A) * (1-sigmoid(A))\n",
    "    dLdA = dLdB * dBdA\n",
    "    dAdV = X.T\n",
    "    dLdV = np.dot(dAdV, dLdA)\n",
    "    W -= dLdW\n",
    "    V -= dLdV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [[1 1 1]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [1 1 0]\n",
      " [0 0 0]\n",
      " [1 0 0]\n",
      " [0 1 1]\n",
      " [1 0 1]]\n",
      "y: [[1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "np.random.seed(1)\n",
    "randX = np.random.choice(range(1,9), size=8, replace=False)\n",
    "mapping_dict = {1:[0,0,0],\n",
    "               2:[0,0,1],\n",
    "               3:[0,1,0],\n",
    "               4:[0,1,1],\n",
    "               5:[1,0,0],\n",
    "               6:[1,0,1],\n",
    "               7:[1,1,0],\n",
    "               8:[1,1,1]}\n",
    "X = []\n",
    "for r in randX:\n",
    "    X.append(mapping_dict[r])\n",
    "\n",
    "\n",
    "y = []\n",
    "randy = np.random.choice(range(1,9), size=8, replace=False)\n",
    "for el in randy:\n",
    "    if el % 2 == 0:\n",
    "        y.append([0])\n",
    "    else:\n",
    "        y.append([1])\n",
    "\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print \"X: %s\" % str(X)\n",
    "print \"y: %s\" % str(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x,deriv=False):\n",
    "\tif(deriv==True):\n",
    "\t    return x*(1-x)\n",
    "\treturn 1/(1+np.exp(-x))\n",
    "\n",
    "V = np.random.randn(3, 4)\n",
    "W = np.random.randn(4, 1)\n",
    "for j in range(60000):\n",
    "    A = np.dot(X,V)\n",
    "    B = nonlin(A)\n",
    "    C = np.dot(B,W)\n",
    "    P = nonlin(C)\n",
    "    L = 0.5 * (y - P) ** 2\n",
    "    if ( j % 10000) == 0:\n",
    "        print \"Error:\" + str(np.mean(np.abs(L)))\n",
    "    dLdP = -1.0 * (y-P)\n",
    "    dPdC = sigmoid(C) * (1-sigmoid(C))\n",
    "    dLdC = dLdP * dPdC\n",
    "    dCdW = B.T\n",
    "    dLdW = np.dot(dCdW, dLdC)\n",
    "    dCdB = W.T\n",
    "    dLdB = dLdC * dCdB\n",
    "    dBdA = sigmoid(A) * (1-sigmoid(A))\n",
    "    dLdA = dLdB * dBdA\n",
    "    dAdV = X.T\n",
    "    dLdV = np.dot(dAdV, dLdA)\n",
    "    W -= dLdW\n",
    "    V -= dLdV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Code changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x,deriv=False):\n",
    "\tif(deriv==True):\n",
    "\t    return x*(1-x)\n",
    "\treturn 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def learn(X, y, num_hidden, iterations):\n",
    "    np.random.seed(2)\n",
    "    V = np.random.randn(X.shape[0], num_hidden)\n",
    "    W = np.random.randn(num_hidden, y.shape[0])\n",
    "    for j in range(60000):\n",
    "        A = np.dot(X,V)\n",
    "        B = sigmoid(A)\n",
    "        C = np.dot(B,W)\n",
    "        P = sigmoid(C)\n",
    "        L = 0.5 * (y - P) ** 2\n",
    "        dLdP = -1.0 * (y-P)\n",
    "        dPdC = sigmoid(C) * (1-sigmoid(C))\n",
    "        dLdC = dLdP * dPdC\n",
    "        dCdW = B.T\n",
    "        dLdW = np.dot(dCdW, dLdC)\n",
    "        dCdB = W.T\n",
    "        dLdB = dLdC * dCdB\n",
    "        dBdA = sigmoid(A) * (1-sigmoid(A))\n",
    "        dLdA = dLdB * dBdA\n",
    "        dAdV = X.T\n",
    "        dLdV = np.dot(dAdV, dLdA)\n",
    "        W -= dLdW\n",
    "        V -= dLdV\n",
    "    return V, W\n",
    "        \n",
    "def predict(X_new, V, W):\n",
    "    A = np.dot(X_new,V)\n",
    "    B = sigmoid(A)\n",
    "    C = np.dot(B,W)\n",
    "    P = sigmoid(C)\n",
    "    return P\n",
    "\n",
    "X_new = [[1, 1, 1], [0, 1, 0]]\n",
    "V, W = learn(X, y)\n",
    "print \"V: %s\" % str(V)\n",
    "print \"W: %s\" % str(W)\n",
    "np.set_printoptions(suppress=True)\n",
    "P = predict(X_new, V, W)\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def learn_simple_net(X, y):\n",
    "    W = np.random.randn(3, 1)\n",
    "    for i in range(50001):\n",
    "        A = np.dot(X, W)\n",
    "        P = sigmoid(A)\n",
    "        L = 0.5 * (y - P) ** 2\n",
    "        dLdP = -1.0 * (y - P)\n",
    "        dPdA = sigmoid(A) * (1.0 - sigmoid(A))\n",
    "        dLdA = dLdP * dPdA\n",
    "        dAdW = X.T\n",
    "        dLdW = np.dot(dAdW, dLdA)\n",
    "        W -= 0.5 * dLdW\n",
    "    return W\n",
    "\n",
    "def predict_simple_net(X_new, W):\n",
    "    A = np.dot(X_new, W)\n",
    "    P = sigmoid(A)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def generate_X_y():\n",
    "    np.random.seed(1)\n",
    "    randX = np.random.choice(range(1,9), size=8, replace=False)\n",
    "    mapping_dict = {1:[0,0,0],\n",
    "                   2:[0,0,1],\n",
    "                   3:[0,1,0],\n",
    "                   4:[0,1,1],\n",
    "                   5:[1,0,0],\n",
    "                   6:[1,0,1],\n",
    "                   7:[1,1,0],\n",
    "                   8:[1,1,1]}\n",
    "    X = []\n",
    "    for r in randX:\n",
    "        X.append(mapping_dict[r])\n",
    "\n",
    "    y = []\n",
    "    randy = np.random.choice(range(1,9), size=8, replace=False)\n",
    "    for el in randy:\n",
    "        if el % 2 == 0:\n",
    "            y.append([0])\n",
    "        else:\n",
    "            y.append([1])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# No bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X, y = generate_X_y()\n",
    "W = learn_simple_net(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_xor = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
    "y_xor = np.array([[1], [0], [0], [1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def learn_simple_net_no_bias(X, y, num_features):\n",
    "    W = np.random.randn(num_features, 1)\n",
    "    for i in range(50001):\n",
    "        A = np.dot(X, W)\n",
    "        P = sigmoid(A)\n",
    "        L = 0.5 * (y - P) ** 2\n",
    "        dLdP = -1.0 * (y - P)\n",
    "        dPdA = sigmoid(A) * (1.0 - sigmoid(A))\n",
    "        dLdA = dLdP * dPdA\n",
    "        dAdW = X.T\n",
    "        dLdW = np.dot(dAdW, dLdA)\n",
    "        W -= 0.5 * dLdW\n",
    "    return W\n",
    "\n",
    "def predict_simple_net_no_bias(X_new, W):\n",
    "    A = np.dot(X_new, W)\n",
    "    P = sigmoid(A)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W = learn_simple_net_no_bias(X_xor, y_xor, 2)\n",
    "print W\n",
    "predict_simple_net_no_bias(X_xor, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "def learn_complex_net(X, y):\n",
    "    np.random.seed(1)\n",
    "    V = np.random.randn(X.shape[1], 3)\n",
    "    W = np.random.randn(3, 1)\n",
    "    for j in range(10000):\n",
    "        A = np.dot(X,V)\n",
    "        B = sigmoid(A)\n",
    "        C = np.dot(B,W)\n",
    "        P = sigmoid(C)\n",
    "        L = 0.5 * (y - P) ** 2\n",
    "        dLdP = -1.0 * (y-P)\n",
    "        dPdC = sigmoid(C) * (1-sigmoid(C))\n",
    "        dLdC = dLdP * dPdC\n",
    "        dCdW = B.T\n",
    "        dLdW = np.dot(dCdW, dLdC)\n",
    "        dCdB = W.T\n",
    "        dLdB = dLdC * dCdB\n",
    "        dBdA = sigmoid(A) * (1-sigmoid(A))\n",
    "        dLdA = dLdB * dBdA\n",
    "        dAdV = X.T\n",
    "        dLdV = np.dot(dAdV, dLdA)\n",
    "        W -= dLdW\n",
    "        V -= dLdV\n",
    "    return V, W\n",
    "\n",
    "V, W = learn_complex_net(X_xor, y_xor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict_complex_net(X_new, V, W):\n",
    "    A = np.dot(X_new,V)\n",
    "    B = sigmoid(A)\n",
    "    C = np.dot(B,W)\n",
    "    P = sigmoid(C)\n",
    "    return P\n",
    "\n",
    "predict_complex_net(X_xor, V, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print \"V: \" + str(np.around(V, 2))\n",
    "print \"W: \" + str(np.around(W, 2))\n",
    "B = sigmoid(np.dot(X_xor, V))\n",
    "print \"B: \" + str(np.around(B, 2))\n",
    "C = np.dot(B, W)\n",
    "print \"C: \" + str(np.around(C, 2))\n",
    "P = sigmoid(C)\n",
    "print \"P: \" + str(np.around(P, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_xor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = np.array([[0,0], [0,1], [1,0], [1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = [[1], [0], [0], [1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def learn_simple_net(X, y, num_features):\n",
    "    W = np.random.randn(num_features, 1)\n",
    "    for i in range(50001):\n",
    "        A = np.dot(X, W)\n",
    "        P = sigmoid(A)\n",
    "        L = 0.5 * (y - P) ** 2\n",
    "        dLdP = -1.0 * (y - P)\n",
    "        dPdA = sigmoid(A) * (1.0 - sigmoid(A))\n",
    "        dLdA = dLdP * dPdA\n",
    "        dAdW = X.T\n",
    "        dLdW = np.dot(dAdW, dLdA)\n",
    "        W -= 0.5 * dLdW\n",
    "    return W\n",
    "\n",
    "W = learn_simple_net(X, y, 2)\n",
    "X_new = X \n",
    "predict_simple_net(X_new, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def learn_complex_net(X, y, num_features):\n",
    "    np.random.seed(2)\n",
    "    V = np.random.randn(num_features, 3)\n",
    "    W = np.random.randn(3, 1)\n",
    "    for j in range(60000):\n",
    "        A = np.dot(X,V)\n",
    "        B = sigmoid(A)\n",
    "        C = np.dot(B,W)\n",
    "        P = sigmoid(C)\n",
    "        L = 0.5 * (y - P) ** 2\n",
    "        dLdP = -1.0 * (y-P)\n",
    "        dPdC = sigmoid(C) * (1-sigmoid(C))\n",
    "        dLdC = dLdP * dPdC\n",
    "        dCdW = B.T\n",
    "        dLdW = np.dot(dCdW, dLdC)\n",
    "        dCdB = W.T\n",
    "        dLdB = dLdC * dCdB\n",
    "        dBdA = sigmoid(A) * (1-sigmoid(A))\n",
    "        dLdA = dLdB * dBdA\n",
    "        dAdV = X.T\n",
    "        dLdV = np.dot(dAdV, dLdA)\n",
    "        W -= dLdW\n",
    "        V -= dLdV\n",
    "    return V, W\n",
    "\n",
    "V, W = learn_complex_net(X, y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_new = X\n",
    "\n",
    "def predict_complex_net(X_new, V, W):\n",
    "    A = np.dot(X_new,V)\n",
    "    B = sigmoid(A)\n",
    "    C = np.dot(B,W)\n",
    "    P = sigmoid(C)\n",
    "    return P\n",
    "\n",
    "predict_complex_net(X_new, V, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Add bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def learn_simple_net(X, y, num_features, num_obs):\n",
    "    W = np.random.randn(num_features, 1)\n",
    "    bias_init = np.random.normal(0, 1)\n",
    "    A_bias = np.full((num_obs, 1), bias_init)\n",
    "    for i in range(50001):\n",
    "        A = np.dot(X, W)\n",
    "        C = A + A_bias\n",
    "        P = sigmoid(C)\n",
    "        L = 0.5 * (y - P) ** 2\n",
    "        dLdP = -1.0 * (y - P)\n",
    "        dPdC = sigmoid(C) * (1.0 - sigmoid(C))\n",
    "        dLdC = dLdP * dPdC\n",
    "        dCdA_bias = 1\n",
    "        dLdA_bias = dLdC * dCdA_bias\n",
    "        dCdA = 1\n",
    "        dLdA = dLdC * dCdA        \n",
    "        dAdW = X.T\n",
    "        dLdW = np.dot(dAdW, dLdA)\n",
    "        A_bias -= 0.5 * np.full((num_obs, 1), np.mean(dLdA_bias))\n",
    "        W -= 0.5 * dLdW\n",
    "    return W, B\n",
    "\n",
    "W, B = learn_simple_net(X, y, 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "A = np.dot(X_new, W)\n",
    "A + B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict_simple_net(X_new, W, A_bias):\n",
    "    A = np.dot(X_new, W)\n",
    "    C = A + A_bias\n",
    "    P = sigmoid(C)\n",
    "    return P\n",
    "\n",
    "predict_simple_net(X_new, W, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Add bias to complex net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def learn_complex_net(X, y, num_features, num_obs):\n",
    "    np.random.seed(2)\n",
    "    V = np.random.randn(num_features, 3)\n",
    "    A_bias_init = np.random.normal(0, 1) \n",
    "    A_bias = np.full((num_obs, 1), A_bias_init)\n",
    "    W = np.random.randn(3, 1)\n",
    "    C_bias_init = np.random.normal(0, 1)\n",
    "    C_bias = np.full((num_obs, 1), C_bias_init)\n",
    "    for j in range(60000):\n",
    "        A = np.dot(X,V)\n",
    "        A_final = A + A_bias\n",
    "        B = sigmoid(A_final)\n",
    "        C = np.dot(B,W)\n",
    "        C_final = C + C_bias\n",
    "        P = sigmoid(C_final)\n",
    "        L = 0.5 * (y - P) ** 2\n",
    "        dLdP = -1.0 * (y-P)\n",
    "        dPdC_final = sigmoid(C_final) * (1-sigmoid(C_final))\n",
    "        dLdC_final = dLdP * dPdC_final\n",
    "        dC_finaldC = 1\n",
    "        dC_finalC_bias = 1\n",
    "        dLdC_bias = dLdC_final * dC_finalC_bias\n",
    "        dLdC = dLdC_final * dC_finaldC \n",
    "        dCdW = B.T\n",
    "        dLdW = np.dot(dCdW, dLdC)\n",
    "        dCdB = W.T\n",
    "        dLdB = dLdC * dCdB\n",
    "        dBdA_final = sigmoid(A_final) * (1-sigmoid(A_final))\n",
    "        dLdA_final = dLdB * dBdA_final\n",
    "        dA_finaldA = 1\n",
    "        dA_finaldA_bias = 1\n",
    "        dLdA_bias = dLdA_final * dA_finaldA_bias \n",
    "        dLdA = dLdA_final * dA_finaldA \n",
    "        dAdV = X.T\n",
    "        dLdV = np.dot(dAdV, dLdA)\n",
    "        C_bias -= 0.5 * np.full((num_obs, 1), np.mean(dLdC_bias)) \n",
    "        A_bias -= 0.5 * np.full((num_obs, 1), np.mean(dLdA_bias)) \n",
    "        W -= 0.5 * dLdW\n",
    "        V -= 0.5 * dLdV\n",
    "    return V, W, np.mean(C_bias), np.mean(A_bias)\n",
    "\n",
    "# V, W, C_bias, A_bias = learn_complex_net(X, y, 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "A "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict_complex_net(X_new, V, W, C_bias, A_bias):\n",
    "    A = np.dot(X_new,V)\n",
    "    A_final = A + A_bias\n",
    "    B = sigmoid(A_final)\n",
    "    C = np.dot(B,W)\n",
    "    C_final = C + C_bias\n",
    "    P = sigmoid(C_final)\n",
    "    return P\n",
    "\n",
    "predict_complex_net(X_new, V, W, C_bias, A_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Testing with complex data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X, y = generate_X_y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "V, W, C_bias, A_bias = learn_complex_net(X, y, 3, 8)\n",
    "X_new = X\n",
    "predict_complex_net(X_new, V, W, C_bias, A_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = np.array([[0,0], [0,1], [1,0], [1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y = [[1], [0], [0], [1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def learn(X, y, num_hidden, num_iterations): \n",
    "    V = np.random.randn(X.shape[0], num_hidden)\n",
    "    W = np.random.randn(num_hidden, y.shape[0])\n",
    "    for j in range(num_iterations):\n",
    "        A = np.dot(X,V)\n",
    "        B = sigmoid(A)\n",
    "        C = np.dot(B,W)\n",
    "        P = sigmoid(C)\n",
    "        L = 0.5 * (y - P) ** 2\n",
    "        dLdP = -1.0 * (y-P)\n",
    "        dPdC = sigmoid(C) * (1-sigmoid(C))\n",
    "        dLdC = dLdP * dPdC\n",
    "        dCdW = B.T\n",
    "        dLdW = np.dot(dCdW, dLdC)\n",
    "        dCdB = W.T\n",
    "        dLdB = dLdC * dCdB\n",
    "        dBdA = sigmoid(A) * (1-sigmoid(A))\n",
    "        dLdA = dLdB * dBdA\n",
    "        dAdV = X.T\n",
    "        dLdV = np.dot(dAdV, dLdA)\n",
    "        W -= dLdW\n",
    "        V -= dLdV\n",
    "    return V, W\n",
    "\n",
    "def predict(X_new, V, W):\n",
    "    A = np.dot(X_new,V)\n",
    "    B = sigmoid(A)\n",
    "    C = np.dot(B,W)\n",
    "    P = sigmoid(C)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict_complex_net(X_new, V, W):\n",
    "    A = np.dot(X_new,V)\n",
    "    B = sigmoid(A)\n",
    "    C = np.dot(B,W)\n",
    "    P = sigmoid(C)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_mesh_boundaries(V, W):\n",
    "    h = .01\n",
    "    x_min, x_max = X[:, 0].min(), X[:, 0].max()\n",
    "    y_min, y_max = X[:, 1].min(), X[:, 1].max()\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    X_new = np.c_[xx.ravel(), yy.ravel()]\n",
    "    Z = predict_complex_net(X_new, V, W)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm, s=100)\n",
    "    plt.xticks(np.arange(0,1.1,1.0))\n",
    "    plt.yticks(np.arange(0,1.1,1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "V, W = learn_complex_net(X, y)\n",
    "plot_mesh_boundaries(V, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    def _setup(self, input_shape, rng):\n",
    "        \"\"\" Setup layer with parameters that are unknown at __init__(). \"\"\"\n",
    "        pass\n",
    "\n",
    "    def fprop(self, input):\n",
    "        \"\"\" Calculate layer output for given input (forward propagation). \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def bprop(self, output_grad):\n",
    "        \"\"\" Calculate input gradient. \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def output_shape(self, input_shape):\n",
    "        \"\"\" Calculate shape of this layer's output.\n",
    "        input_shape[0] is the number of samples in the input.\n",
    "        input_shape[1:] is the shape of the feature.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Linear(Layer, ParamMixin):\n",
    "    def __init__(self, n_out, weight_scale, weight_decay=0.0):\n",
    "        self.n_out = n_out\n",
    "        self.weight_scale = weight_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers, rng=None):\n",
    "        self.layers = layers\n",
    "        if rng is None:\n",
    "            rng = np.random.RandomState()\n",
    "        self.rng = rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def _setup(self, X, Y):\n",
    "    # Setup layers sequentially\n",
    "    next_shape = X.shape\n",
    "    for layer in self.layers:\n",
    "        layer._setup(next_shape, self.rng)\n",
    "        next_shape = layer.output_shape(next_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict(self, X):\n",
    "    \"\"\" Calculate an output Y for the given input X. \"\"\"\n",
    "    X_next = X\n",
    "    for layer in self.layers:\n",
    "        X_next = layer.fprop(X_next)\n",
    "    prediction = X_next\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def error(self, X, Y):\n",
    "    \"\"\" Calculate error on the given data. \"\"\"\n",
    "    prediction = self.predict(X)\n",
    "    loss = 0.5 * (prediction - Y) ** 2\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def backprop(self, error):\n",
    "    \"\"\" Calculate an output Y for the given input X. \"\"\"\n",
    "    # Back propagation of partial derivatives\n",
    "    \n",
    "    for layer in reversed(self.layers[:-1]):\n",
    "        next_grad = layer.bprop(next_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "l = [1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "l.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def learn_simple_net(X, y):\n",
    "    W = np.random.randn(3, 1)\n",
    "    for i in range(50001):\n",
    "        A = np.dot(X, W)\n",
    "        P = sigmoid(A)\n",
    "        L = 0.5 * (y - P) ** 2\n",
    "        dLdP = -1.0 * (y - P)\n",
    "        dPdA = sigmoid(A) * (1.0 - sigmoid(A))\n",
    "        dLdA = dLdP * dPdA\n",
    "        dAdW = X.T\n",
    "        dLdW = np.dot(dAdW, dLdA)\n",
    "        W -= 0.5 * dLdW\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Way to think of this is: \n",
    "\n",
    "One layer:\n",
    "\n",
    "Takes in X as input. It, as a layer, has weights, a way of combining those weights with the input X, and an activation function. \n",
    "\n",
    "It will have \"fprop\" as a class method.\n",
    "\n",
    "And backprop. This method takes in \"error\" as an input and returns:\n",
    "The input to the next level, which does not apply in this case since it is a one layer network.\n",
    "The weight updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "    \n",
    "    def forwardpass(self, X):\n",
    "        \"\"\" Calculate an output Y for the given input X. \"\"\"\n",
    "        X_next = X\n",
    "        for layer in self.layers:\n",
    "            X_next = layer.fprop(X_next)\n",
    "        prediction = X_next\n",
    "        return prediction\n",
    "    \n",
    "    def loss(self, prediction, Y):\n",
    "        \"\"\" Calculate error on the given data. \"\"\"\n",
    "        loss = 0.5 * (Y - prediction) ** 2\n",
    "        print -1.0 * (Y - prediction)\n",
    "        return -1.0 * (Y - prediction)\n",
    "    \n",
    "    def backpropogate(self, loss):\n",
    "        \"\"\" Calculate an output Y for the given input X. \"\"\"\n",
    "        loss_next = loss\n",
    "        for layer in reversed(self.layers):\n",
    "            loss_next = layer.bprop(loss_next)\n",
    "        return loss\n",
    "    \n",
    "class Layer(object):\n",
    "    def _setup(self, input_shape, rng):\n",
    "        \"\"\" Setup layer with parameters that are unknown at __init__(). \"\"\"\n",
    "        pass\n",
    "\n",
    "    def fprop(self, input):\n",
    "        \"\"\" Calculate layer output for given input (forward propagation). \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def bprop(self, output_grad):\n",
    "        \"\"\" Calculate input gradient. \"\"\"\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "def sigmoid(x, bprop=False):\n",
    "    if bprop:\n",
    "        s = sigmoid(x)\n",
    "        return s*(1-s)\n",
    "    else:\n",
    "        return 1.0/(1.0+np.exp(-x))\n",
    "\n",
    "        \n",
    "class Linear(Layer):\n",
    "    def __init__(self, n_in, n_out, input_layer=False):\n",
    "        self.input_layer = input_layer\n",
    "        self.W = np.random.randn(n_in, n_out)\n",
    "        self.activation_function = sigmoid\n",
    "        \n",
    "    def fprop(self, layer_input):\n",
    "        self.layer_input = layer_input\n",
    "        self.activation_input = np.dot(layer_input, self.W)\n",
    "        return self.activation_function(self.activation_input, bprop=False)\n",
    "\n",
    "    def bprop(self, layer_grad):\n",
    "        dPdAi = self.activation_function(self.activation_input, bprop=True)\n",
    "        dLdAi = layer_grad * dPdAi\n",
    "        dAodAi = self.layer_input.T\n",
    "        W_new = self.W - np.dot(dAodAi, dLdAi)\n",
    "        output_grad = np.dot(dLdAi, self.W.T)\n",
    "        self.W = W_new      \n",
    "        return output_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# nn1 = NeuralNetwork(\n",
    "#     layers=[\n",
    "#         Linear(n_in=3,\n",
    "#                n_out=1)\n",
    "#         ]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# X = np.array([  [0,0,1],\n",
    "#                 [0,1,1],\n",
    "#                 [1,0,1],\n",
    "#                 [1,1,1] ])\n",
    "    \n",
    "# # output dataset            \n",
    "# y = np.array([[0,0,1,1]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for i in range(1000):\n",
    "#     prediction = nn1.forwardpass(X)\n",
    "#     print prediction\n",
    "#     loss = nn1.loss(prediction, y)\n",
    "#     nn1.backpropogate(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nn2 = NeuralNetwork(\n",
    "    layers=[\n",
    "        Linear(n_in=3,\n",
    "               n_out=4,\n",
    "               input_layer=True),\n",
    "        Linear(n_in=4,\n",
    "               n_out=1)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [[1 0 1]\n",
      " [0 0 0]\n",
      " [0 1 0]\n",
      " [1 1 0]\n",
      " [1 1 1]\n",
      " [0 1 1]\n",
      " [0 0 1]\n",
      " [1 0 0]]\n",
      "y: [[1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "randX = random.sample(range(1,9), 8)\n",
    "mapping_dict = {1:[0,0,0],\n",
    "               2:[0,0,1],\n",
    "               3:[0,1,0],\n",
    "               4:[0,1,1],\n",
    "               5:[1,0,0],\n",
    "               6:[1,0,1],\n",
    "               7:[1,1,0],\n",
    "               8:[1,1,1]}\n",
    "X = []\n",
    "for r in randX:\n",
    "    X.append(mapping_dict[r])\n",
    "\n",
    "y = []\n",
    "randy = random.sample(range(1,9), 8)\n",
    "for el in randy:\n",
    "    if el % 2 == 0:\n",
    "        y.append([0])\n",
    "    else:\n",
    "        y.append([1])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print \"X: %s\" % str(X)\n",
    "print \"y: %s\" % str(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def learn(X, y): \n",
    "    V = np.random.randn(X.shape[1], 4)\n",
    "    W = np.random.randn(4, 1)\n",
    "    for j in range(10000):\n",
    "        A = np.dot(X,V)\n",
    "        B = sigmoid(A)\n",
    "        P = np.dot(B,W)\n",
    "        L = 0.5 * (y - P) ** 2\n",
    "        dLdP = -1.0 * (y-P)\n",
    "        dPdW = B.T\n",
    "        dLdW = np.dot(dPdW, dLdP)\n",
    "        dPdB = W.T\n",
    "        dLdB = np.dot(dLdP, dPdB)\n",
    "        dBdA = sigmoid(A) * (1-sigmoid(A))\n",
    "        dLdA = dLdB * dBdA\n",
    "        dAdV = X.T\n",
    "        dLdV = np.dot(dAdV, dLdA)\n",
    "        W -= dLdW\n",
    "        V -= dLdV\n",
    "    return V, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict_complex_net(X, V, W):\n",
    "    A = np.dot(X,V)\n",
    "    B = sigmoid(A)\n",
    "    P = np.dot(B,W)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "V, W = learn_complex_net(X, y)\n",
    "P = predict_complex_net(X, V, W)\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "def train_neural_net(net, X, y, epochs=10):\n",
    "    for i in range(epochs):\n",
    "        prediction = net.forwardpass(X)\n",
    "        loss = net.loss(prediction, y)\n",
    "        net.backpropogate(loss)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_neural_net(nn2, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nn3 = NeuralNetwork(\n",
    "    layers=[\n",
    "        Linear(n_in=3,\n",
    "               n_out=7,\n",
    "               input_layer=True),\n",
    "        Linear(n_in=7,\n",
    "               n_out=4),\n",
    "        Linear(n_in=4,\n",
    "               n_out=1)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "for i in range(10002):\n",
    "    prediction = nn3.forwardpass(X)\n",
    "    loss = nn3.loss(prediction, y)\n",
    "    nn3.backpropogate(loss)\n",
    "    if i % 10000 == 1:\n",
    "        print prediction - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "import numpy as np\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = mnist.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_clean = (data - data.min()) / (data.max() - data.min()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "target = mnist.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "out = np.zeros((len(target), 10))\n",
    "for i in range(len(target)):\n",
    "    out[i][int(target[i])] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 1.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "    \n",
    "    def forwardpass(self, X):\n",
    "        \"\"\" Calculate an output Y for the given input X. \"\"\"\n",
    "        X_next = X\n",
    "        for layer in self.layers:\n",
    "            X_next = layer.fprop(X_next)\n",
    "        prediction = X_next\n",
    "        return prediction\n",
    "    \n",
    "    def loss(self, prediction, Y):\n",
    "        \"\"\" Calculate error on the given data. \"\"\"\n",
    "        loss = 0.5 * (Y - prediction) ** 2\n",
    "        return -1.0 * (Y - prediction)\n",
    "    \n",
    "    def backpropogate(self, loss):\n",
    "        \"\"\" Calculate an output Y for the given input X. \"\"\"\n",
    "        loss_next = loss\n",
    "        for layer in reversed(self.layers):\n",
    "            loss_next = layer.bprop(loss_next)\n",
    "        return loss\n",
    "    \n",
    "class Layer(object):\n",
    "    def _setup(self, input_shape, rng):\n",
    "        \"\"\" Setup layer with parameters that are unknown at __init__(). \"\"\"\n",
    "        pass\n",
    "\n",
    "    def fprop(self, input):\n",
    "        \"\"\" Calculate layer output for given input (forward propagation). \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def bprop(self, output_grad):\n",
    "        \"\"\" Calculate input gradient. \"\"\"\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "def sigmoid(x, bprop=False):\n",
    "    if bprop:\n",
    "        s = sigmoid(x)\n",
    "        return s*(1-s)\n",
    "    else:\n",
    "        return 1.0/(1.0+np.exp(-x))\n",
    "\n",
    "        \n",
    "class Linear(Layer):\n",
    "    def __init__(self, n_in, n_out, activation_function):\n",
    "        self.W = np.random.normal(loc=0.0, scale=0.01, size=(n_in, n_out))\n",
    "        self.activation_function = activation_function\n",
    "        \n",
    "    def fprop(self, layer_input):\n",
    "        self.layer_input = layer_input\n",
    "#         print self.layer_input.shape\n",
    "        self.activation_input = np.dot(layer_input, self.W)\n",
    "#         print self.activation_input.shape\n",
    "        return self.activation_function(self.activation_input, bprop=False)\n",
    "\n",
    "    def bprop(self, layer_grad):\n",
    "        dPdAi = self.activation_function(self.activation_input, bprop=True)\n",
    "        dLdAi = layer_grad * dPdAi\n",
    "        dAodAi = self.layer_input.T\n",
    "        W_new = self.W - 0.001 * np.dot(dAodAi, dLdAi)\n",
    "        output_grad = np.dot(dLdAi, self.W.T)\n",
    "        self.W = W_new      \n",
    "        return output_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "nn_mnist = NeuralNetwork(\n",
    "    layers=[\n",
    "        Linear(n_in=784,\n",
    "               n_out=30,\n",
    "               activation_function=sigmoid),\n",
    "        Linear(n_in=30,\n",
    "               n_out=20,\n",
    "               activation_function=sigmoid),\n",
    "        Linear(n_in=20,\n",
    "               n_out=10,\n",
    "               activation_function=sigmoid)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def learn_neural_net(net, X, y):\n",
    "    pred = net.forwardpass(X)\n",
    "    loss = net.loss(pred, y)\n",
    "    net.backpropogate(loss)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for j in range(70000):\n",
    "    i = np.random.randint(0,70000)\n",
    "    X = np.array(data_clean[i], ndmin=2)\n",
    "    y = np.array(out[i], ndmin=2)\n",
    "    learn_neural_net(nn_mnist, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def learn(X, y):\n",
    "    np.random.seed(2)\n",
    "    V = np.random.randn(784, 30)\n",
    "    W = np.random.randn(30, 10)\n",
    "    for j in range(70000):\n",
    "        i = np.random.randint(0,70000)\n",
    "        X = np.array(data_clean[i], ndmin=2)\n",
    "        y = np.array(out[i], ndmin=2)\n",
    "        A = np.dot(X,V)\n",
    "        B = sigmoid(A)\n",
    "        C = np.dot(B,W)\n",
    "        P = sigmoid(C)\n",
    "        sum_P = np.sum(P)\n",
    "        L = 0.5 * (y - P) ** 2\n",
    "#         if ( j % 10000) == 0:\n",
    "#             print \"Error:\" + str(np.mean(np.abs(L)))\n",
    "        dLdP = -1.0 * (y-P)\n",
    "        dPdC = sigmoid(C) * (1-sigmoid(C))\n",
    "        dLdC = dLdP * dPdC\n",
    "        dCdW = B.T\n",
    "        dLdW = np.dot(dCdW, dLdC)\n",
    "        dCdB = W.T\n",
    "        dLdB = np.dot(dLdC, dCdB)\n",
    "        dBdA = sigmoid(A) * (1-sigmoid(A))\n",
    "        dLdA = dLdB * dBdA\n",
    "        dAdV = X.T\n",
    "        dLdV = np.dot(dAdV, dLdA)\n",
    "        W -= dLdW\n",
    "        V -= dLdV\n",
    "    return V, W\n",
    "        \n",
    "def predict(X_new, V, W):\n",
    "    A = np.dot(X_new,V)\n",
    "    B = sigmoid(A)\n",
    "    C = np.dot(B,W)\n",
    "    P = sigmoid(C)\n",
    "    return P\n",
    "\n",
    "# X_new = [[1, 1, 1], [0, 1, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "V, W = learn(data_clean, out)\n",
    "P = predict(data_clean, V, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for el in P:\n",
    "    pred = np.argmax(el)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36252857142857142"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds == target) * 1.0 / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def learn_complex_net(X, y, num_features, num_obs):\n",
    "    np.random.seed(2)\n",
    "    V = np.random.randn(num_features, 30)\n",
    "    A_bias_init = np.random.normal(0, 1) \n",
    "    A_bias = np.full((num_obs, 1), A_bias_init)\n",
    "    W = np.random.randn(30, 1)\n",
    "    C_bias_init = np.random.normal(0, 1)\n",
    "    C_bias = np.full((num_obs, 1), C_bias_init)\n",
    "    for i in range(60000):\n",
    "        i = np.random.randint(0,70000)\n",
    "        X = np.array(data_clean[i], ndmin=2)\n",
    "        y = np.array(out[i], ndmin=2)\n",
    "        A = np.dot(X,V)\n",
    "        A_final = A + A_bias\n",
    "        B = sigmoid(A_final)\n",
    "        C = np.dot(B,W)\n",
    "        C_final = C + C_bias\n",
    "        P = sigmoid(C_final)\n",
    "        L = 0.5 * (y - P) ** 2\n",
    "        dLdP = -1.0 * (y-P)\n",
    "        dPdC_final = sigmoid(C_final) * (1-sigmoid(C_final))\n",
    "        dLdC_final = dLdP * dPdC_final\n",
    "        dC_finaldC = 1\n",
    "        dC_finalC_bias = 1\n",
    "        dLdC_bias = dLdC_final * dC_finalC_bias\n",
    "        dLdC = dLdC_final * dC_finaldC \n",
    "        dCdW = B.T\n",
    "        dLdW = np.dot(dCdW, dLdC)\n",
    "        dCdB = W.T\n",
    "        dLdB = dLdC * dCdB\n",
    "        dBdA_final = sigmoid(A_final) * (1-sigmoid(A_final))\n",
    "        dLdA_final = dLdB * dBdA_final\n",
    "        dA_finaldA = 1\n",
    "        dA_finaldA_bias = 1\n",
    "        dLdA_bias = dLdA_final * dA_finaldA_bias \n",
    "        dLdA = dLdA_final * dA_finaldA \n",
    "        dAdV = X.T\n",
    "        dLdV = np.dot(dAdV, dLdA)\n",
    "        C_bias -= 0.5 * np.full((num_obs, 1), np.mean(dLdC_bias)) \n",
    "        A_bias -= 0.5 * np.full((num_obs, 1), np.mean(dLdA_bias)) \n",
    "        W -= 0.5 * dLdW\n",
    "        V -= 0.5 * dLdV\n",
    "    return V, W, np.mean(C_bias), np.mean(A_bias)\n",
    "\n",
    "# V, W, C_bias, A_bias = learn_complex_net(X, y, 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(70000):\n",
    "    learn_complex_net(data_clean, out, 784, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "    \n",
    "    def forwardpass(self, X):\n",
    "        \"\"\" Calculate an output Y for the given input X. \"\"\"\n",
    "        X_next = X\n",
    "        for layer in self.layers:\n",
    "            X_next = layer.fprop(X_next)\n",
    "        prediction = X_next\n",
    "        return prediction\n",
    "    \n",
    "    def loss(self, prediction, Y):\n",
    "        \"\"\" Calculate error on the given data. \"\"\"\n",
    "        if len(Y.shape) == 1:\n",
    "            Y = Y.reshape((Y.shape[0], 1))\n",
    "        mse = 0.5 * (Y - prediction) ** 2\n",
    "        loss = -1.0 * (Y - prediction)\n",
    "        if len(loss.shape) == 1:\n",
    "            loss = loss.reshape((1, 1))\n",
    "        return loss\n",
    "    \n",
    "    def backpropogate(self, loss):\n",
    "        \"\"\" Calculate an output Y for the given input X. \"\"\"\n",
    "        loss_next = loss\n",
    "        for layer in reversed(self.layers):\n",
    "            loss_next = layer.bprop(loss_next)\n",
    "        return loss\n",
    "    \n",
    "class Layer(object):\n",
    "    def _setup(self, input_shape, rng):\n",
    "        \"\"\" Setup layer with parameters that are unknown at __init__(). \"\"\"\n",
    "        pass\n",
    "\n",
    "    def fprop(self, input):\n",
    "        \"\"\" Calculate layer output for given input (forward propagation). \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def bprop(self, output_grad):\n",
    "        \"\"\" Calculate input gradient. \"\"\"\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "def sigmoid(x, bprop=False):\n",
    "    if bprop:\n",
    "        s = sigmoid(x)\n",
    "        return s*(1-s)\n",
    "    else:\n",
    "        return 1.0/(1.0+np.exp(-x))\n",
    "    \n",
    "def linear(x, bprop=False):\n",
    "    if bprop:\n",
    "        return x\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "class Linear(Layer):\n",
    "    def __init__(self, n_in, n_out, activation_function, lr=1):\n",
    "        self.W = np.random.normal(loc=0.0, scale=1, size=(n_in, n_out))\n",
    "        self.activation_function = activation_function\n",
    "        self.lr = lr\n",
    "        \n",
    "    def fprop(self, layer_input):\n",
    "        self.layer_input = np.array(layer_input, ndmin=2)\n",
    "        self.activation_input = np.dot(layer_input, self.W)\n",
    "        return self.activation_function(self.activation_input, bprop=False)\n",
    "\n",
    "    def bprop(self, layer_grad):\n",
    "        dPdAi = self.activation_function(self.activation_input, bprop=True)\n",
    "        dLdAi = layer_grad * dPdAi\n",
    "        dAodAi = self.layer_input.T\n",
    "        W_update = np.dot(dAodAi, dLdAi)\n",
    "        output_grad = np.dot(dLdAi, self.W.T) \n",
    "        self.W -= self.lr * W_update\n",
    "        return output_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "def train_neural_net(net, X, y):\n",
    "    prediction = net.forwardpass(X)\n",
    "    loss = net.loss(prediction, y)\n",
    "    net.backpropogate(loss)\n",
    "    return prediction    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.105314285714\n",
      "5000\n",
      "0.199185714286\n",
      "10000\n",
      "0.203785714286\n",
      "15000\n",
      "0.266828571429\n",
      "20000\n",
      "0.291228571429\n",
      "25000\n",
      "0.270771428571\n",
      "30000\n",
      "0.3078\n",
      "35000\n",
      "0.318085714286\n",
      "40000\n",
      "0.330785714286\n",
      "45000\n",
      "0.3379\n",
      "50000\n",
      "0.337057142857\n",
      "55000\n",
      "0.320857142857\n",
      "60000\n",
      "0.361785714286\n",
      "65000\n",
      "0.349028571429\n",
      "70000\n",
      "0.336885714286\n",
      "75000\n",
      "0.353271428571\n",
      "80000\n",
      "0.369157142857\n",
      "85000\n",
      "0.354328571429\n",
      "90000\n",
      "0.349457142857\n",
      "95000\n",
      "0.351614285714\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "for iters in range(0, 100000, 5000):\n",
    "    nn_mnist = NeuralNetwork(\n",
    "    layers=[\n",
    "        Linear(n_in=784,\n",
    "               n_out=30,\n",
    "               activation_function=sigmoid),\n",
    "        Linear(n_in=30,\n",
    "               n_out=10,\n",
    "               activation_function=sigmoid)\n",
    "        ]\n",
    "    )\n",
    "    for i in range(iters):\n",
    "        i = np.random.randint(0,70000)\n",
    "        X = np.array(data_clean[i], ndmin=2)\n",
    "        y = np.array(out[i], ndmin=2)\n",
    "        train_neural_net(nn_mnist, X, y)\n",
    "    preds = nn_mnist.forwardpass(data_clean)\n",
    "    preds_list = []\n",
    "    for el in preds:\n",
    "        pred = np.argmax(el)\n",
    "        preds_list.append(pred)\n",
    "    accuracy = sum(preds_list == target) * 1.0 / len(preds_list)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print iters\n",
    "    print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0971428571429\n",
      "5000\n",
      "0.168642857143\n",
      "10000\n",
      "0.211328571429\n",
      "15000\n",
      "0.2798\n",
      "20000\n",
      "0.291628571429\n",
      "25000\n",
      "0.297928571429\n",
      "30000\n",
      "0.300442857143\n",
      "35000\n",
      "0.295857142857\n",
      "40000\n",
      "0.3162\n",
      "45000\n",
      "0.348442857143\n",
      "50000\n",
      "0.350385714286\n",
      "55000\n",
      "0.346785714286\n",
      "60000\n",
      "0.343542857143\n",
      "65000\n",
      "0.360985714286\n",
      "70000\n",
      "0.336071428571\n",
      "75000\n",
      "0.345957142857\n",
      "80000\n",
      "0.354757142857\n",
      "85000\n",
      "0.353528571429\n",
      "90000\n",
      "0.368857142857\n",
      "95000\n",
      "0.356128571429\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "for iters in range(0, 100000, 5000):\n",
    "    nn_mnist = NeuralNetwork(\n",
    "    layers=[\n",
    "        Linear(n_in=784,\n",
    "               n_out=25,\n",
    "               activation_function=sigmoid),\n",
    "        Linear(n_in=25,\n",
    "               n_out=10,\n",
    "               activation_function=sigmoid)\n",
    "        ]\n",
    "    )\n",
    "    for i in range(iters):\n",
    "        i = np.random.randint(0,70000)\n",
    "        X = np.array(data_clean[i], ndmin=2)\n",
    "        y = np.array(out[i], ndmin=2)\n",
    "        train_neural_net(nn_mnist, X, y)\n",
    "    preds = nn_mnist.forwardpass(data_clean)\n",
    "    preds_list = []\n",
    "    for el in preds:\n",
    "        pred = np.argmax(el)\n",
    "        preds_list.append(pred)\n",
    "    accuracy = sum(preds_list == target) * 1.0 / len(preds_list)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print iters\n",
    "    print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0968285714286\n",
      "5000\n",
      "0.154442857143\n",
      "10000\n",
      "0.232942857143\n",
      "15000\n",
      "0.264\n",
      "20000\n",
      "0.277557142857\n",
      "25000\n",
      "0.306285714286\n",
      "30000\n",
      "0.331085714286\n",
      "35000\n",
      "0.334942857143\n",
      "40000\n",
      "0.326185714286\n",
      "45000\n",
      "0.354328571429\n",
      "50000\n",
      "0.357\n",
      "55000\n",
      "0.350685714286\n",
      "60000\n",
      "0.357985714286\n",
      "65000\n",
      "0.3645\n",
      "70000\n",
      "0.349771428571\n",
      "75000\n",
      "0.371357142857\n",
      "80000\n",
      "0.361642857143\n",
      "85000\n",
      "0.3474\n",
      "90000\n",
      "0.3525\n",
      "95000\n",
      "0.372628571429\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "for iters in range(0, 100000, 5000):\n",
    "    nn_mnist = NeuralNetwork(\n",
    "    layers=[\n",
    "        Linear(n_in=784,\n",
    "               n_out=20,\n",
    "               activation_function=sigmoid),\n",
    "        Linear(n_in=20,\n",
    "               n_out=10,\n",
    "               activation_function=sigmoid)\n",
    "        ]\n",
    "    )\n",
    "    for i in range(iters):\n",
    "        i = np.random.randint(0,70000)\n",
    "        X = np.array(data_clean[i], ndmin=2)\n",
    "        y = np.array(out[i], ndmin=2)\n",
    "        train_neural_net(nn_mnist, X, y)\n",
    "    preds = nn_mnist.forwardpass(data_clean)\n",
    "    preds_list = []\n",
    "    for el in preds:\n",
    "        pred = np.argmax(el)\n",
    "        preds_list.append(pred)\n",
    "    accuracy = sum(preds_list == target) * 1.0 / len(preds_list)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print iters\n",
    "    print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "accuracy_list = []\n",
    "for iters in range(0, 100000, 5000):\n",
    "    nn_mnist = NeuralNetwork(\n",
    "    layers=[\n",
    "        Linear(n_in=784,\n",
    "               n_out=25,\n",
    "               activation_function=sigmoid),\n",
    "        Linear(n_in=25,\n",
    "               n_out=10,\n",
    "               activation_function=sigmoid)\n",
    "        ]\n",
    "    )\n",
    "    for i in range(iters):\n",
    "        i = np.random.randint(0,70000)\n",
    "        X = np.array(data_clean[i], ndmin=2)\n",
    "        y = np.array(out[i], ndmin=2)\n",
    "        train_neural_net(nn_mnist, X, y)\n",
    "    preds = nn_mnist.forwardpass(data_clean)\n",
    "    preds_list = []\n",
    "    for el in preds:\n",
    "        pred = np.argmax(el)\n",
    "        preds_list.append(pred)\n",
    "    accuracy = sum(preds_list == target) * 1.0 / len(preds_list)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print iters\n",
    "    print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0974142857143\n",
      "5000\n",
      "0.136828571429\n",
      "10000\n",
      "0.223857142857\n",
      "15000\n",
      "0.234642857143\n",
      "20000\n",
      "0.2807\n",
      "25000\n",
      "0.2809\n",
      "30000\n",
      "0.291314285714\n",
      "35000\n",
      "0.308071428571\n",
      "40000\n",
      "0.317228571429\n",
      "45000\n",
      "0.309457142857\n",
      "50000\n",
      "0.325085714286\n",
      "55000\n",
      "0.333714285714\n",
      "60000\n",
      "0.337042857143\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-426d198dcafa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         )\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m70000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_clean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "for iters in range(0, 100000, 5000):\n",
    "    nn_mnist = NeuralNetwork(\n",
    "        layers=[\n",
    "            Linear(n_in=784,\n",
    "                   n_out=30,\n",
    "                   activation_function=sigmoid, \n",
    "                   lr = 0.5),\n",
    "            Linear(n_in=30,\n",
    "                   n_out=10,\n",
    "                   activation_function=sigmoid,\n",
    "                   lr=0.5)\n",
    "            ]\n",
    "        )\n",
    "    for i in range(iters):\n",
    "        i = np.random.randint(0,70000)\n",
    "        X = np.array(data_clean[i], ndmin=2)\n",
    "        y = np.array(out[i], ndmin=2)\n",
    "        train_neural_net(nn_mnist, X, y)\n",
    "    preds = nn_mnist.forwardpass(data_clean)\n",
    "    preds_list = []\n",
    "    for el in preds:\n",
    "        pred = np.argmax(el)\n",
    "        preds_list.append(pred)\n",
    "    accuracy = sum(preds_list == target) * 1.0 / len(preds_list)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print iters\n",
    "    print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0961428571429\n",
      "5000\n",
      "0.130114285714\n",
      "10000\n",
      "0.1617\n",
      "15000\n",
      "0.196971428571\n",
      "20000\n",
      "0.216314285714\n",
      "25000\n",
      "0.2265\n",
      "30000\n",
      "0.276185714286\n",
      "35000\n",
      "0.288042857143\n",
      "40000\n",
      "0.323342857143\n",
      "45000\n",
      "0.303385714286\n",
      "50000\n",
      "0.306814285714\n",
      "55000\n",
      "0.322928571429\n",
      "60000\n",
      "0.322642857143\n",
      "65000\n",
      "0.336585714286\n",
      "70000\n",
      "0.3277\n",
      "75000\n",
      "0.315414285714\n",
      "80000\n",
      "0.3385\n",
      "85000\n",
      "0.351128571429\n",
      "90000\n",
      "0.349414285714\n",
      "95000\n",
      "0.343685714286\n"
     ]
    }
   ],
   "source": [
    "accuracy_list = []\n",
    "for iters in range(0, 100000, 5000):\n",
    "    nn_mnist = NeuralNetwork(\n",
    "    layers=[\n",
    "        Linear(n_in=784,\n",
    "               n_out=30,\n",
    "               activation_function=sigmoid),\n",
    "        Linear(n_in=30,\n",
    "               n_out=10,\n",
    "               activation_function=sigmoid),\n",
    "        Linear(n_in=10,\n",
    "               n_out=10,\n",
    "               activation_function=sigmoid),            \n",
    "        ]\n",
    "    )\n",
    "    for i in range(iters):\n",
    "        i = np.random.randint(0,70000)\n",
    "        X = np.array(data_clean[i], ndmin=2)\n",
    "        y = np.array(out[i], ndmin=2)\n",
    "        train_neural_net(nn_mnist, X, y)\n",
    "    preds = nn_mnist.forwardpass(data_clean)\n",
    "    preds_list = []\n",
    "    for el in preds:\n",
    "        pred = np.argmax(el)\n",
    "        preds_list.append(pred)\n",
    "    accuracy = sum(preds_list == target) * 1.0 / len(preds_list)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print iters\n",
    "    print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.096142857142857141,\n",
       " 0.13011428571428571,\n",
       " 0.16170000000000001,\n",
       " 0.19697142857142858,\n",
       " 0.21631428571428571,\n",
       " 0.22650000000000001,\n",
       " 0.27618571428571431,\n",
       " 0.28804285714285716,\n",
       " 0.32334285714285715,\n",
       " 0.30338571428571426,\n",
       " 0.30681428571428571,\n",
       " 0.32292857142857145,\n",
       " 0.32264285714285712,\n",
       " 0.33658571428571427,\n",
       " 0.32769999999999999,\n",
       " 0.3154142857142857,\n",
       " 0.33850000000000002,\n",
       " 0.3511285714285714,\n",
       " 0.34941428571428573,\n",
       " 0.34368571428571426]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.98598562,  0.00032984,  0.00302274, ...,  0.01935958,\n",
       "         0.00154548,  0.00158472],\n",
       "       [ 0.78680536,  0.24285232,  0.00795582, ...,  0.00455463,\n",
       "         0.01069252,  0.0011276 ],\n",
       "       [ 0.38486731,  0.00377702,  0.00880326, ...,  0.00074757,\n",
       "         0.25050105,  0.00025249],\n",
       "       ..., \n",
       "       [ 0.06552646,  0.00380538,  0.0000917 , ...,  0.00965458,\n",
       "         0.00148867,  0.47006883],\n",
       "       [ 0.01364895,  0.02672996,  0.0027566 , ...,  0.02580113,\n",
       "         0.00509027,  0.01911549],\n",
       "       [ 0.0365897 ,  0.00277089,  0.00086004, ...,  0.11624484,\n",
       "         0.00679373,  0.32249287]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = nn_mnist.forwardpass(data_clean)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "preds_list = []\n",
    "for el in preds:\n",
    "    pred = np.argmax(el)\n",
    "    preds_list.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35858571428571429"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds_list == target) * 1.0 / len(preds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def learn_complex_net(X, y): \n",
    "    V = np.random.randn(X.shape[1], 4)\n",
    "    W = np.random.randn(4, 1)\n",
    "    for j in range(10000):\n",
    "        A = np.dot(X,V)\n",
    "        B = sigmoid(A)\n",
    "        C = np.dot(B,W)\n",
    "        P = sigmoid(C)\n",
    "        L = 0.5 * (y - P) ** 2\n",
    "        dLdP = -1.0 * (y-P)\n",
    "        dPdC = sigmoid(C) * (1-sigmoid(C))\n",
    "        dLdC = dLdP * dPdC\n",
    "        dCdW = B.T\n",
    "        dLdW = np.dot(dCdW, dLdC)\n",
    "        dCdB = W.T\n",
    "        dLdB = np.dot(dLdC, dCdB)\n",
    "        dBdA = sigmoid(A) * (1-sigmoid(A))\n",
    "        dLdA = dLdB * dBdA\n",
    "        dAdV = X.T\n",
    "        dLdV = np.dot(dAdV, dLdA)\n",
    "        W -= dLdW\n",
    "        V -= dLdV\n",
    "    return V, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict_complex_net(X_new, V, W):\n",
    "    A = np.dot(X_new,V)\n",
    "    B = sigmoid(A)\n",
    "    C = np.dot(B,W)\n",
    "    P = sigmoid(C)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "V, W = learn_complex_net(X, y)\n",
    "pred = predict_complex_net(X, V, W)\n",
    "y - pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
