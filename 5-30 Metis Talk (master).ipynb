{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:**\n",
    "\n",
    "* Clean up\n",
    "* Write helper function for initializing indices, training weights.\n",
    "* Do Batch Normalization!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(precision=2, threshold=2)\n",
    "import random\n",
    "random.seed(1)\n",
    "from neural_net import (NeuralNetwork, \n",
    "                        Layer, \n",
    "                        Linear)\n",
    "from activation_functions import sigmoid\n",
    "from helpers import (get_mnist_X_Y, \n",
    "                     momentum_range,\n",
    "                     _plot_learning_rate_decay)\n",
    "from python_custom.misc import (numpy_round, \n",
    "                                list_index_wraparound)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural nets here are defined as a series of layers, each of which gets values from a prior layer and then feeds that information through an activation function into the next layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline neural net - TODO: write helper functions for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y = get_mnist_X_Y()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_mnist = NeuralNetwork(\n",
    "    layers=[\n",
    "        Linear(n_in=784,\n",
    "               n_out=50,\n",
    "               activation_function=sigmoid, \n",
    "               random_seed=1),\n",
    "        Linear(n_in=50,\n",
    "               n_out=10,\n",
    "               activation_function=sigmoid, \n",
    "               random_seed=2)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: make this a class method\n",
    "def neural_net_pass(net, x, y):\n",
    "    pred = net.forwardpass(x)\n",
    "    loss = net.loss(pred, y)\n",
    "    net.backpropogate(loss)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_prop = 0.9\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, \n",
    "    test_size=1-train_prop, \n",
    "    random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = X.shape[0]\n",
    "train_size = int(train_prop * data_size)\n",
    "indices = list(range(train_size))\n",
    "random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_mnist = NeuralNetwork(\n",
    "    layers=[\n",
    "        Linear(n_in=784,\n",
    "               n_out=50,\n",
    "               activation_function=sigmoid, \n",
    "               random_seed=1),\n",
    "        Linear(n_in=50,\n",
    "               n_out=10,\n",
    "               activation_function=sigmoid, \n",
    "               random_seed=2)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in indices:\n",
    "    x = np.array(X_train[i], ndmin=2)\n",
    "    y = np.array(Y_train[i], ndmin=2)\n",
    "    neural_net_pass(nn_mnist, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90342857142857147"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = nn_mnist.forwardpass(X_test)\n",
    "preds = [np.argmax(x) for x in P]\n",
    "actuals = [np.argmax(x) for x in Y_test]\n",
    "\n",
    "accuracy = sum(np.array(preds) == np.array(actuals)) * 1.0 / len(preds)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_mnist_deep = NeuralNetwork(\n",
    "    layers=[\n",
    "        Linear(n_in=784,\n",
    "               n_out=100,\n",
    "               activation_function=sigmoid, \n",
    "               random_seed=1),\n",
    "        Linear(n_in=100,\n",
    "               n_out=25,\n",
    "               activation_function=sigmoid, \n",
    "               random_seed=2),\n",
    "        Linear(n_in=25,\n",
    "               n_out=10,\n",
    "               activation_function=sigmoid, \n",
    "               random_seed=3)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in indices:\n",
    "    x = np.array(X_train[i], ndmin=2)\n",
    "    y = np.array(Y_train[i], ndmin=2)\n",
    "    neural_net_pass(nn_mnist_deep, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88914285714285712"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = nn_mnist_deep.forwardpass(X_test)\n",
    "preds = [np.argmax(x) for x in P]\n",
    "actuals = [np.argmax(x) for x in Y_test]\n",
    "\n",
    "accuracy = sum(np.array(preds) == np.array(actuals)) * 1.0 / len(preds)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn_mnist_deep_2 = NeuralNetwork(\n",
    "    layers=[\n",
    "        Linear(n_in=784,\n",
    "               n_out=150,\n",
    "               activation_function=sigmoid, \n",
    "               random_seed=1),\n",
    "        Linear(n_in=150,\n",
    "               n_out=50,\n",
    "               activation_function=sigmoid, \n",
    "               random_seed=2),\n",
    "        Linear(n_in=50,\n",
    "               n_out=10,\n",
    "               activation_function=sigmoid, \n",
    "               random_seed=3)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in indices:\n",
    "    x = np.array(X_train[i], ndmin=2)\n",
    "    y = np.array(Y_train[i], ndmin=2)\n",
    "    neural_net_pass(nn_mnist_deep_2, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87514285714285711"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P = nn_mnist_deep_2.forwardpass(X_test)\n",
    "preds = [np.argmax(x) for x in P]\n",
    "actuals = [np.argmax(x) for x in Y_test]\n",
    "\n",
    "accuracy = sum(np.array(preds) == np.array(actuals)) * 1.0 / len(preds)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy goes does with additional weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_plot_learning_rate_decay(1, 0.01, train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "start_learning_rate = 2\n",
    "end_learning_rate = 0.5\n",
    "learning_rates = momentum_range(start_learning_rate, end_learning_rate, train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nn_mnist = NeuralNetwork(\n",
    "    layers=[\n",
    "        Linear(n_in=784,\n",
    "               n_out=50,\n",
    "               activation_function=sigmoid, \n",
    "               random_seed=1, \n",
    "               learning_rates=learning_rates),\n",
    "        Linear(n_in=50,\n",
    "               n_out=10,\n",
    "               activation_function=sigmoid, \n",
    "               random_seed=2, \n",
    "               learning_rates=learning_rates)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in indices:\n",
    "    x = np.array(X_train[i], ndmin=2)\n",
    "    y = np.array(Y_train[i], ndmin=2)\n",
    "    neural_net_pass(nn_mnist, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "P = nn_mnist.forwardpass(X_test)\n",
    "preds = [np.argmax(x) for x in P]\n",
    "actuals = [np.argmax(x) for x in Y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "accuracy = sum(np.array(preds) == np.array(actuals)) * 1.0 / len(preds)\n",
    "numpy_round(accuracy, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Test momentum factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_momentum_factor(factor):\n",
    "    start_learning_rate = 1.0 * factor \n",
    "    end_learning_rate = 1.0 / factor\n",
    "    learning_rates = momentum_range(start_learning_rate, end_learning_rate, train_size)\n",
    "    \n",
    "    nn_mnist = NeuralNetwork(\n",
    "    layers=[\n",
    "        Linear(n_in=784,\n",
    "               n_out=50,\n",
    "               activation_function=sigmoid, \n",
    "               random_seed=1, \n",
    "               learning_rates=learning_rates),\n",
    "        Linear(n_in=50,\n",
    "               n_out=10,\n",
    "               activation_function=sigmoid, \n",
    "               random_seed=2, \n",
    "               learning_rates=learning_rates)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    for i in indices:\n",
    "        x = np.array(X_train[i], ndmin=2)\n",
    "        y = np.array(Y_train[i], ndmin=2)\n",
    "        neural_net_pass(nn_mnist, x, y)\n",
    "        \n",
    "    P = nn_mnist.forwardpass(X_test)\n",
    "    preds = [np.argmax(x) for x in P]\n",
    "    actuals = [np.argmax(x) for x in Y_test]\n",
    "    \n",
    "    accuracy = sum(np.array(preds) == np.array(actuals)) * 1.0 / len(preds)\n",
    "    return numpy_round(accuracy, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "factors = np.arange(1, 5, 0.1)\n",
    "accuracies = []\n",
    "for factor in factors:\n",
    "    print(factor)\n",
    "    accuracy = test_momentum_factor(factor)\n",
    "    accuracies.append(accuracy)\n",
    "    print(accuracy)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# accuracy_df = pd.DataFrame({'factors': factors, 'accuracies': accuracies}).sort_values('accuracies', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from python_custom import s3_helpers\n",
    "# nn_bucket = s3_helpers.get_s3_bucket('neural-net-experiments')\n",
    "# s3_helpers.add_object_to_bucket(nn_bucket, 'mnist_accuracies_momentum', accuracy_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight initializaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rates = momentum_range(1.0 * 2.2, 1.0 / 2.2, train_size)\n",
    "nn_mnist = NeuralNetwork(\n",
    "    layers=[\n",
    "        Linear(n_in=784,\n",
    "               n_out=50,\n",
    "               activation_function=sigmoid, \n",
    "               random_seed=1, \n",
    "               learning_rates=learning_rates,\n",
    "               weights_scale='square-root'),\n",
    "        Linear(n_in=50,\n",
    "               n_out=10,\n",
    "               activation_function=sigmoid, \n",
    "               random_seed=2, \n",
    "               learning_rates=learning_rates,\n",
    "               weights_scale='square-root')\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in indices:\n",
    "    x = np.array(X_train[i], ndmin=2)\n",
    "    y = np.array(Y_train[i], ndmin=2)\n",
    "    neural_net_pass(nn_mnist, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = nn_mnist.forwardpass(X_test)\n",
    "preds = [np.argmax(x) for x in P]\n",
    "actuals = [np.argmax(x) for x in Y_test]\n",
    "\n",
    "accuracy = sum(np.array(preds) == np.array(actuals)) * 1.0 / len(preds)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_weight_scales(weight_scale):\n",
    "    learning_rates = momentum_range(1.0 * 2.2, 1.0 / 2.2, train_size)\n",
    "    nn_mnist = NeuralNetwork(\n",
    "        layers=[\n",
    "            Linear(n_in=784,\n",
    "                   n_out=50,\n",
    "                   activation_function=sigmoid, \n",
    "                   random_seed=1, \n",
    "                   learning_rates=learning_rates,\n",
    "                   weights_scale=weight_scale),\n",
    "            Linear(n_in=50,\n",
    "                   n_out=10,\n",
    "                   activation_function=sigmoid, \n",
    "                   random_seed=2, \n",
    "                   learning_rates=learning_rates,\n",
    "                   weights_scale=(50.0 / 784.0) * weight_scale)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    for i in indices:\n",
    "        x = np.array(X_train[i], ndmin=2)\n",
    "        y = np.array(Y_train[i], ndmin=2)\n",
    "        neural_net_pass(nn_mnist, x, y)\n",
    "        \n",
    "    P = nn_mnist.forwardpass(X_test)\n",
    "    preds = [np.argmax(x) for x in P]\n",
    "    actuals = [np.argmax(x) for x in Y_test]\n",
    "\n",
    "    accuracy = sum(np.array(preds) == np.array(actuals)) * 1.0 / len(preds)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_scales = [2.0 ** x for x in np.arange(0, -20, -1)]\n",
    "accuracies = []\n",
    "for scale in weight_scales:\n",
    "    print(scale)\n",
    "    accuracy = test_weight_scales(scale)\n",
    "    accuracies.append(accuracy)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.0 / 784.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(weight_scales, accuracies)\n",
    "plt.semilogx(basex=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scales_df = pd.DataFrame({'scales': weight_scales, 'accuracies': accuracies}).sort_values('accuracies', ascending=False)\n",
    "from python_custom import s3_helpers\n",
    "nn_bucket = s3_helpers.get_s3_bucket('neural-net-experiments')\n",
    "# s3_helpers.add_object_to_bucket(nn_bucket, 'mnist_accuracies_weight_scales', scales_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncated Normal Distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = momentum_range(1.0 * 2.2, 1.0 / 2.2, train_size)\n",
    "nn_mnist = NeuralNetwork(\n",
    "    layers=[\n",
    "        Linear(n_in=784,\n",
    "               n_out=50,\n",
    "               activation_function=sigmoid, \n",
    "               random_seed=1, \n",
    "               learning_rates=learning_rates,\n",
    "               weights_scale=2 ** -13, \n",
    "               weights_shape=\"truncated\"),\n",
    "        Linear(n_in=50,\n",
    "               n_out=10,\n",
    "               activation_function=sigmoid, \n",
    "               random_seed=2, \n",
    "               learning_rates=learning_rates,\n",
    "               weights_scale=2 ** -13,\n",
    "               weights_shape=\"truncated\")\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93442857142857139"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in indices:\n",
    "    x = np.array(X_train[i], ndmin=2)\n",
    "    y = np.array(Y_train[i], ndmin=2)\n",
    "    neural_net_pass(nn_mnist, x, y)\n",
    "\n",
    "P = nn_mnist.forwardpass(X_test)\n",
    "preds = [np.argmax(x) for x in P]\n",
    "actuals = [np.argmax(x) for x in Y_test]\n",
    "\n",
    "accuracy = sum(np.array(preds) == np.array(actuals)) * 1.0 / len(preds)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_truncation_normal(truncation):\n",
    "    learning_rates = momentum_range(1.0 * 2.2, 1.0 / 2.2, train_size)\n",
    "    nn_mnist = NeuralNetwork(\n",
    "        layers=[\n",
    "            Linear(n_in=784,\n",
    "                   n_out=50,\n",
    "                   activation_function=sigmoid, \n",
    "                   random_seed=1, \n",
    "                   learning_rates=learning_rates,\n",
    "                   weights_scale=2 ** -13, \n",
    "                   weights_shape=\"truncated\", \n",
    "                   truncation=truncation),\n",
    "            Linear(n_in=50,\n",
    "                   n_out=10,\n",
    "                   activation_function=sigmoid, \n",
    "                   random_seed=2, \n",
    "                   learning_rates=learning_rates,\n",
    "                   weights_scale=2 ** -13,\n",
    "                   weights_shape=\"truncated\", \n",
    "                   truncation=truncation)\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    for i in indices:\n",
    "        x = np.array(X_train[i], ndmin=2)\n",
    "        y = np.array(Y_train[i], ndmin=2)\n",
    "        neural_net_pass(nn_mnist, x, y)\n",
    "\n",
    "    P = nn_mnist.forwardpass(X_test)\n",
    "    preds = [np.argmax(x) for x in P]\n",
    "    actuals = [np.argmax(x) for x in Y_test]\n",
    "\n",
    "    accuracy = sum(np.array(preds) == np.array(actuals)) * 1.0 / len(preds)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.937571428571\n",
      "1.1\n",
      "0.926857142857\n",
      "1.2\n",
      "0.932285714286\n",
      "1.3\n",
      "0.932857142857\n",
      "1.4\n",
      "0.925428571429\n",
      "1.5\n",
      "0.932571428571\n",
      "1.6\n",
      "0.934\n",
      "1.7\n",
      "0.936142857143\n",
      "1.8\n",
      "0.934571428571\n",
      "1.9\n",
      "0.925857142857\n",
      "2.0\n",
      "0.936142857143\n",
      "2.1\n",
      "0.928428571429\n",
      "2.2\n",
      "0.924571428571\n",
      "2.3\n",
      "0.928571428571\n",
      "2.4\n",
      "0.926714285714\n",
      "2.5\n",
      "0.928142857143\n",
      "2.6\n",
      "0.933857142857\n",
      "2.7\n",
      "0.929428571429\n",
      "2.8\n",
      "0.927142857143\n",
      "2.9\n",
      "0.934142857143\n"
     ]
    }
   ],
   "source": [
    "truncations = np.arange(1, 3, 0.1)\n",
    "accuracies = []\n",
    "for truncation in truncations:\n",
    "    print(truncation)\n",
    "    accuracy = test_truncation_normal(truncation)\n",
    "    accuracies.append(accuracy)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1056acb70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD8CAYAAACGsIhGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWSEnCzMzK+RkYWZmhf4/u91DxCM7YscAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x104691278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(truncations, accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from python_custom import s3_helpers\n",
    "nn_bucket = s3_helpers.get_s3_bucket('neural-net-experiments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracies</th>\n",
       "      <th>scales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.936286</td>\n",
       "      <td>0.000122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.935429</td>\n",
       "      <td>0.003906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.934429</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.934429</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.934429</td>\n",
       "      <td>0.007812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.934000</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.932571</td>\n",
       "      <td>0.000061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.931857</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.931571</td>\n",
       "      <td>0.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.931143</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.930429</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.929714</td>\n",
       "      <td>0.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.929143</td>\n",
       "      <td>0.000977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.928286</td>\n",
       "      <td>0.000488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.927571</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.927000</td>\n",
       "      <td>0.001953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.926714</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.925429</td>\n",
       "      <td>0.000244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.923714</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.914571</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracies    scales\n",
       "13    0.936286  0.000122\n",
       "8     0.935429  0.003906\n",
       "19    0.934429  0.000002\n",
       "18    0.934429  0.000004\n",
       "7     0.934429  0.007812\n",
       "15    0.934000  0.000031\n",
       "14    0.932571  0.000061\n",
       "2     0.931857  0.250000\n",
       "6     0.931571  0.015625\n",
       "3     0.931143  0.125000\n",
       "17    0.930429  0.000008\n",
       "5     0.929714  0.031250\n",
       "10    0.929143  0.000977\n",
       "11    0.928286  0.000488\n",
       "16    0.927571  0.000015\n",
       "9     0.927000  0.001953\n",
       "4     0.926714  0.062500\n",
       "12    0.925429  0.000244\n",
       "1     0.923714  0.500000\n",
       "0     0.914571  1.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_helpers.get_object_from_bucket(nn_bucket, 'mnist_accuracies_weight_scales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def set_learning_rate(learning_rates, iteration):\n",
    "    if len(learning_rates) == 0:\n",
    "        current_learning_rate = 1\n",
    "    else: \n",
    "        current_learning_rate = list_index_wraparound(learning_rates, \n",
    "                                                      iteration)\n",
    "        print(\"In this iteration of backprop, the learning rate is \", \n",
    "              current_learning_rate)\n",
    "    return current_learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learning_rates = [0.2, 0.1]\n",
    "iteration = 0\n",
    "set_learning_rate(learning_rates, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "P = nn_mnist.forwardpass(X_test)\n",
    "preds = [np.argmax(x) for x in P]\n",
    "actuals = [np.argmax(x) for x in Y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "100px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
